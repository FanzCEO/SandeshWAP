#!/bin/bash

# Simple Enterprise Performance Validation
# Reliable testing without complex process monitoring

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

API_BASE="http://localhost:5000"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
RESULTS_FILE="simple_perf_results_${TIMESTAMP}.txt"

echo -e "${BLUE}======================================${NC}"
echo -e "${BLUE}  ENTERPRISE PERFORMANCE VALIDATION  ${NC}"
echo -e "${BLUE}======================================${NC}"
echo "Started at: $(date)"
echo

# Initialize results
cat > "$RESULTS_FILE" <<EOF
ENTERPRISE PERFORMANCE VALIDATION REPORT
Generated: $(date)
API Base: $API_BASE

RESULTS:
========
EOF

# Test basic endpoints with timing
echo -e "${GREEN}=== RESPONSE TIME TESTING ===${NC}"

echo "Testing basic endpoints..."
for i in {1..5}; do
    health_time=$(curl -w "%{time_total}" -s -o /dev/null $API_BASE/api)
    project_time=$(curl -w "%{time_total}" -s -o /dev/null $API_BASE/api/project)
    files_time=$(curl -w "%{time_total}" -s -o /dev/null $API_BASE/api/files)
    
    echo "Round $i: Health=${health_time}s, Project=${project_time}s, Files=${files_time}s"
    echo "Round $i: Health=${health_time}s, Project=${project_time}s, Files=${files_time}s" >> "$RESULTS_FILE"
done

echo -e "\n${GREEN}=== FILE OPERATIONS TESTING ===${NC}"

# Test file operations
echo "Testing file operations..."
echo "Creating test file..."
create_time=$(curl -w "%{time_total}" -s -o /dev/null -X POST -H "Content-Type: application/json" \
    -d '{"path":"perf_test.txt","content":"Performance test content"}' \
    $API_BASE/api/file/create)

echo "Reading test file..."
read_time=$(curl -w "%{time_total}" -s -o /dev/null "$API_BASE/api/file?path=perf_test.txt")

echo "Updating test file..."
update_time=$(curl -w "%{time_total}" -s -o /dev/null -X POST -H "Content-Type: application/json" \
    -d '{"path":"perf_test.txt","content":"Updated content"}' \
    $API_BASE/api/file)

echo "File operations: Create=${create_time}s, Read=${read_time}s, Update=${update_time}s"
echo "File operations: Create=${create_time}s, Read=${read_time}s, Update=${update_time}s" >> "$RESULTS_FILE"

echo -e "\n${GREEN}=== CONCURRENT LOAD TESTING ===${NC}"

# Simple concurrent test
echo "Testing concurrent requests..."
concurrent_start=$(date +%s.%N)

# Run 20 concurrent requests
for i in {1..20}; do
    curl -s -o /dev/null "$API_BASE/api" &
done
wait

concurrent_end=$(date +%s.%N)
concurrent_duration=$(echo "$concurrent_end - $concurrent_start" | bc -l)

echo "20 concurrent requests completed in: ${concurrent_duration}s"
echo "Throughput: $(echo "scale=2; 20 / $concurrent_duration" | bc -l) req/s"
echo "Concurrent test: duration=${concurrent_duration}s, throughput=$(echo "scale=2; 20 / $concurrent_duration" | bc -l) req/s" >> "$RESULTS_FILE"

echo -e "\n${GREEN}=== LARGE FILE TESTING ===${NC}"

# Test with larger content
echo "Testing large file handling..."
large_content=$(printf 'A%.0s' {1..10000})  # 10KB content
large_create_time=$(curl -w "%{time_total}" -s -o /dev/null -X POST -H "Content-Type: application/json" \
    -d "{\"path\":\"large_test.txt\",\"content\":\"$large_content\"}" \
    $API_BASE/api/file/create)

large_read_time=$(curl -w "%{time_total}" -s -o /dev/null "$API_BASE/api/file?path=large_test.txt")

echo "Large file ops: Create=${large_create_time}s, Read=${large_read_time}s"
echo "Large file ops: Create=${large_create_time}s, Read=${large_read_time}s" >> "$RESULTS_FILE"

echo -e "\n${GREEN}=== SUSTAINED LOAD TESTING ===${NC}"

# Run sustained load for 2 minutes
echo "Running sustained load test (120 seconds)..."
sustained_start=$(date +%s)
request_count=0

while [ $(($(date +%s) - sustained_start)) -lt 120 ]; do
    curl -s -o /dev/null "$API_BASE/api" &
    curl -s -o /dev/null "$API_BASE/api/project" &
    request_count=$((request_count + 2))
    sleep 0.5
    
    # Progress indicator every 30 seconds
    elapsed=$(($(date +%s) - sustained_start))
    if [ $((elapsed % 30)) -eq 0 ] && [ $elapsed -gt 0 ]; then
        echo "  Progress: ${elapsed}s elapsed, ${request_count} requests sent"
    fi
done
wait

sustained_end=$(date +%s)
sustained_duration=$((sustained_end - sustained_start))
avg_rps=$(echo "scale=2; $request_count / $sustained_duration" | bc -l)

echo "Sustained load test: ${request_count} requests in ${sustained_duration}s (${avg_rps} req/s)"
echo "Sustained load: requests=${request_count}, duration=${sustained_duration}s, avg_rps=${avg_rps}" >> "$RESULTS_FILE"

echo -e "\n${GREEN}=== ERROR HANDLING TESTING ===${NC}"

# Test error conditions
echo "Testing error handling..."
error_404_time=$(curl -w "%{time_total}" -s -o /dev/null "$API_BASE/api/nonexistent" || echo "0.100")
error_file_time=$(curl -w "%{time_total}" -s -o /dev/null "$API_BASE/api/file?path=nonexistent.txt" || echo "0.100")

echo "Error handling: 404=${error_404_time}s, File not found=${error_file_time}s"
echo "Error handling: 404=${error_404_time}s, File not found=${error_file_time}s" >> "$RESULTS_FILE"

echo -e "\n${GREEN}=== MEMORY MONITORING ===${NC}"

# Simple memory check
echo "Checking system memory usage..."
initial_memory=$(ps -o rss -p $(pgrep -f "server/index.ts") | tail -n +2 | head -n 1 || echo "0")
echo "Current Node.js memory usage: ${initial_memory}KB"
echo "Memory usage: ${initial_memory}KB" >> "$RESULTS_FILE"

echo -e "\n${GREEN}=== CLEANUP ===${NC}"

# Cleanup test files
echo "Cleaning up test files..."
curl -s -X DELETE -H "Content-Type: application/json" -d '{"path":"perf_test.txt"}' "$API_BASE/api/file" >/dev/null 2>&1
curl -s -X DELETE -H "Content-Type: application/json" -d '{"path":"large_test.txt"}' "$API_BASE/api/file" >/dev/null 2>&1

echo -e "\n${GREEN}=== FINAL ASSESSMENT ===${NC}"

# Simple assessment logic
cat >> "$RESULTS_FILE" <<EOF

FINAL ASSESSMENT:
================
EOF

# Parse the fastest times from the tests
health_best=$(grep "Round" "$RESULTS_FILE" | cut -d'=' -f2 | cut -d's' -f1 | sort -n | head -1)
create_time_val=$(grep "File operations:" "$RESULTS_FILE" | cut -d'=' -f2 | cut -d's' -f1)
best_rps_val=$(echo $avg_rps)

production_ready="true"
grade="A"
issues=()

# Check if health check is under 50ms
if (( $(echo "$health_best > 0.050" | bc -l) )); then
    production_ready="false"
    grade="B"
    issues+=("Health check time (${health_best}s) > 50ms threshold")
fi

# Check if file operations are under 200ms  
if (( $(echo "$create_time_val > 0.200" | bc -l) )); then
    production_ready="false"
    grade="C" 
    issues+=("File operations time (${create_time_val}s) > 200ms threshold")
fi

# Check throughput
if (( $(echo "$best_rps_val < 10" | bc -l) )); then
    grade="C"
    issues+=("Low throughput (${best_rps_val} req/s) < 10 req/s minimum")
fi

echo "Performance Grade: $grade"
echo "Production Ready: $production_ready"

if [ ${#issues[@]} -gt 0 ]; then
    echo -e "${YELLOW}Issues Found:${NC}"
    for issue in "${issues[@]}"; do
        echo "  - $issue"
    done
else
    echo -e "${GREEN}âœ“ All performance metrics pass enterprise requirements${NC}"
fi

cat >> "$RESULTS_FILE" <<EOF
Performance Grade: $grade
Production Ready: $production_ready
Best Health Check Time: ${health_best}s
File Operations Time: ${create_time_val}s
Sustained Throughput: ${best_rps_val} req/s

ENTERPRISE READINESS STATUS: $([ "$production_ready" = "true" ] && echo "PASSED" || echo "NEEDS OPTIMIZATION")
EOF

echo
echo -e "${BLUE}Performance validation completed!${NC}"
echo "Detailed results saved to: $RESULTS_FILE"
echo "Final grade: $grade"
echo "Production ready: $production_ready"

# Show key metrics summary
echo
echo -e "${BLUE}KEY METRICS SUMMARY:${NC}"
echo "- Fastest health check: ${health_best}s (target: <0.050s)"  
echo "- File operations: ${create_time_val}s (target: <0.200s)"
echo "- Sustained throughput: ${best_rps_val} req/s (target: >10 req/s)"
echo "- Memory usage: ${initial_memory}KB"
echo "- Overall grade: $grade"